{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Loading\n",
    "data = r'/content/drive/MyDrive/LikeLion/ML/data/bmi.csv'\n",
    "df = pd.read_csv(data, skiprows=3)\n",
    "\n",
    "df.shape  # (20000, 3)\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "df.isnull().sum()  # 결측치는 없음\n",
    "\n",
    "# 이상치 확인\n",
    "zscore_threshold = 1.8\n",
    "df.loc[np.abs(stats.zscore(df[\"height\"])) >= zscore_threshold]\n",
    "df.loc[np.abs(stats.zscore(df[\"height\"])) >= zscore_threshold]\n",
    "df.loc[np.abs(stats.zscore(df[\"height\"])) >= zscore_threshold]\n",
    "\n",
    "# x, t 데이터 나누기\n",
    "x_data = df[['height', 'weight']].values  # 2차원\n",
    "t_data = df['label'].values\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "x_data_norm = scaler.fit_transform(x_data)\n",
    "\n",
    "# 데이터 분할\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = train_test_split(x_data_norm,\n",
    "                                                                                  t_data,\n",
    "                                                                                  stratify=t_data,\n",
    "                                                                                  test_size=0.3,\n",
    "                                                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sklearn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9855\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "sklearn_model = linear_model.LogisticRegression()\n",
    "\n",
    "sklearn_model.fit(x_data_train_norm,\n",
    "                  t_data_train)\n",
    "\n",
    "predict_value = sklearn_model.predict(x_data_test_norm)\n",
    "\n",
    "# 평가는 accuracy\n",
    "result = accuracy_score(t_data_test, predict_value)\n",
    "\n",
    "print(result)  # 0.9855\n",
    "\n",
    "# prediction\n",
    "height = 187\n",
    "weight = 80\n",
    "my_state = np.array([[height, weight]])\n",
    "my_result = sklearn_model.predict(scaler.transform(my_state))\n",
    "\n",
    "print(my_result)  # [1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module import\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Model\n",
    "keras_model = Sequential()\n",
    "\n",
    "# Layers\n",
    "keras_model.add(Flatten(input_shape={2,}))\n",
    "keras_model.add(Dense(units=3, activation=\"softmax\"))\n",
    "\n",
    "# Compile\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "                    loss=\"sparse_categorical_crossentropy\",  # 입력을 one-hot encoding으로 해줘야 함 => sparse\n",
    "                    metrics=['acc'])\n",
    "\n",
    "# 학습\n",
    "keras_model.fit(x_data_train_norm,\n",
    "                t_data_train,\n",
    "                epochs=200,\n",
    "                verbose=1,\n",
    "                validation_split=0.2)\n",
    "\n",
    "# 마지막 학습 결과\n",
    "# 350/350 [==============================] - 1s 2ms/step - loss: 0.0636 - acc: 0.9813 - val_loss: 0.0548 - val_acc: 0.9843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0569 - acc: 0.9853\n",
      "[0.056868188083171844, 0.9853333234786987]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[2.3042600e-07 9.9349678e-01 6.5029864e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model_eval = keras_model.evaluate(x_data_test_norm,\n",
    "                                  t_data_test)\n",
    "\n",
    "print(model_eval)  # [0.056868188083171844, 0.9853333234786987]\n",
    "\n",
    "# prediction\n",
    "height = 187\n",
    "weight = 80\n",
    "my_state = np.array([[height, weight]])\n",
    "my_result = keras_model.predict(scaler.transform(my_state))\n",
    "\n",
    "print(my_result)  # [[2.3042600e-07 9.9349678e-01 6.5029864e-03]] => 2번째의 값이 가장 크므로 [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [참고] 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        thin       0.50      1.00      0.67         1\n",
      "      normal       0.00      0.00      0.00         1\n",
      "         fat       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.56      0.49         5\n",
      "weighted avg       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "t_true = [0, 1, 2, 2, 2]\n",
    "t_pred = [0, 0, 2, 2, 1]\n",
    "\n",
    "label_names = ['thin', 'normal', 'fat']\n",
    "\n",
    "print(classification_report(t_true, t_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris\n",
    "- 붓꽃은 3가지 종이 있음\n",
    "- setosa, versicolor, verginica\n",
    "- 붓꽃의 꽃받침과 꽃잎의 길이와 너비에 따라서 품종이 결정\n",
    "- 데이터는 총 150개의 데이터\n",
    "- 꽃받침(sepal), 꽃잎(petal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a46434ad-25a1-4048-95c5-e6db0a6e8bda\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.118129</td>\n",
       "      <td>0.873738</td>\n",
       "      <td>0.820620</td>\n",
       "      <td>0.786971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>-0.118129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.426028</td>\n",
       "      <td>-0.362894</td>\n",
       "      <td>-0.422987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>0.873738</td>\n",
       "      <td>-0.426028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962772</td>\n",
       "      <td>0.949402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>0.820620</td>\n",
       "      <td>-0.362894</td>\n",
       "      <td>0.962772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.786971</td>\n",
       "      <td>-0.422987</td>\n",
       "      <td>0.949402</td>\n",
       "      <td>0.956514</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a46434ad-25a1-4048-95c5-e6db0a6e8bda')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a46434ad-25a1-4048-95c5-e6db0a6e8bda button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a46434ad-25a1-4048-95c5-e6db0a6e8bda');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2ae18b08-8845-4708-a6b1-d8899331c4d2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ae18b08-8845-4708-a6b1-d8899331c4d2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2ae18b08-8845-4708-a6b1-d8899331c4d2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              sepal_length  sepal_width  petal_length  petal_width    target\n",
       "sepal_length      1.000000    -0.118129      0.873738     0.820620  0.786971\n",
       "sepal_width      -0.118129     1.000000     -0.426028    -0.362894 -0.422987\n",
       "petal_length      0.873738    -0.426028      1.000000     0.962772  0.949402\n",
       "petal_width       0.820620    -0.362894      0.962772     1.000000  0.956514\n",
       "target            0.786971    -0.422987      0.949402     0.956514  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "# print(iris.data)  # x_data, 꽃받침과 꽃잎의 길이와 너비\n",
    "# print(iris.feature_names)  # ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "# print(iris.target)  # t_data\n",
    "# print(iris.target_names)  # ['setosa' 'versicolor' 'virginica']\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names.append('target'))\n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "df['target'] = iris.target\n",
    "df.shape  # (150, 5)\n",
    "\n",
    "# 결측치 확인\n",
    "df.isnull().sum()  # 결측치는 존재하지 않음\n",
    "\n",
    "# 중복데이터 확인\n",
    "# 일반적으로 중복 데이터는 지우는 것이 맞음\n",
    "# 중복 데이터가 있어야 하는 경우도 있으므로 확인 필요\n",
    "df.duplicated().sum()  # 1, 중복행 존재\n",
    "df[df.duplicated()]  # index 142\n",
    "df = df.drop_duplicates()  # 149 rows × 4 columns\n",
    "\n",
    "# 다중공선성을 파악하기 위한 상관분석\n",
    "# [주의] 상관성은 인과관계가 아닌 연관성만 알려줌\n",
    "display(df.corr())  # sepal_length와 petal_length, petal_width의 상관성 높음\n",
    "\n",
    "x_data = df.drop('target', axis=1, inplace=False).values\n",
    "t_data = df['target'].values.reshape(-1, 1)\n",
    "\n",
    "# 이번 학습에서는 이상치 확인 생략\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "x_data_norm = scaler.fit_transform(x_data)\n",
    "\n",
    "# 데이터 분할\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = train_test_split(x_data_norm,\n",
    "                                                                                  t_data,\n",
    "                                                                                  stratify=t_data,\n",
    "                                                                                  test_size=0.3,\n",
    "                                                                                  random_state=42)\n",
    "\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tensorflow Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 97ms/step - loss: 0.9892 - acc: 0.5542 - val_loss: 0.9035 - val_acc: 0.5714\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8469 - acc: 0.6747 - val_loss: 0.7822 - val_acc: 0.5714\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7221 - acc: 0.6867 - val_loss: 0.7519 - val_acc: 0.5714\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6625 - acc: 0.6867 - val_loss: 0.6861 - val_acc: 0.5714\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5893 - acc: 0.6867 - val_loss: 0.5920 - val_acc: 0.6190\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5371 - acc: 0.7831 - val_loss: 0.5194 - val_acc: 1.0000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5120 - acc: 0.9398 - val_loss: 0.4824 - val_acc: 1.0000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4813 - acc: 0.9157 - val_loss: 0.4712 - val_acc: 0.7619\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4553 - acc: 0.8072 - val_loss: 0.4654 - val_acc: 0.6667\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4315 - acc: 0.8193 - val_loss: 0.4290 - val_acc: 0.8571\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4119 - acc: 0.8554 - val_loss: 0.3970 - val_acc: 0.9524\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4007 - acc: 0.9277 - val_loss: 0.3735 - val_acc: 1.0000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3867 - acc: 0.9398 - val_loss: 0.3717 - val_acc: 0.9048\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3728 - acc: 0.8795 - val_loss: 0.3758 - val_acc: 0.9048\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3666 - acc: 0.8554 - val_loss: 0.3655 - val_acc: 0.9048\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3543 - acc: 0.8675 - val_loss: 0.3300 - val_acc: 0.9524\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3450 - acc: 0.9398 - val_loss: 0.3085 - val_acc: 1.0000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3368 - acc: 0.9518 - val_loss: 0.3068 - val_acc: 0.9524\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3270 - acc: 0.9398 - val_loss: 0.3017 - val_acc: 0.9524\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3195 - acc: 0.9398 - val_loss: 0.2976 - val_acc: 0.9524\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3127 - acc: 0.9398 - val_loss: 0.2840 - val_acc: 0.9524\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3073 - acc: 0.9398 - val_loss: 0.2679 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2996 - acc: 0.9518 - val_loss: 0.2592 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2951 - acc: 0.9518 - val_loss: 0.2524 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2893 - acc: 0.9398 - val_loss: 0.2457 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2843 - acc: 0.9639 - val_loss: 0.2324 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2800 - acc: 0.9639 - val_loss: 0.2380 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2725 - acc: 0.9398 - val_loss: 0.2335 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2685 - acc: 0.9398 - val_loss: 0.2288 - val_acc: 1.0000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2637 - acc: 0.9398 - val_loss: 0.2189 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2594 - acc: 0.9518 - val_loss: 0.2087 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2577 - acc: 0.9759 - val_loss: 0.1968 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2522 - acc: 0.9759 - val_loss: 0.2027 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2476 - acc: 0.9518 - val_loss: 0.2082 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2455 - acc: 0.9398 - val_loss: 0.2036 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2410 - acc: 0.9398 - val_loss: 0.1887 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2446 - acc: 0.9759 - val_loss: 0.1739 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2337 - acc: 0.9759 - val_loss: 0.1829 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2352 - acc: 0.9639 - val_loss: 0.1979 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2313 - acc: 0.9398 - val_loss: 0.1831 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2285 - acc: 0.9639 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2228 - acc: 0.9759 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2201 - acc: 0.9639 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2164 - acc: 0.9639 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2138 - acc: 0.9639 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2110 - acc: 0.9639 - val_loss: 0.1512 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2089 - acc: 0.9759 - val_loss: 0.1470 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2067 - acc: 0.9759 - val_loss: 0.1460 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2048 - acc: 0.9639 - val_loss: 0.1472 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2019 - acc: 0.9639 - val_loss: 0.1422 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1997 - acc: 0.9639 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1989 - acc: 0.9759 - val_loss: 0.1305 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1956 - acc: 0.9759 - val_loss: 0.1327 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1944 - acc: 0.9639 - val_loss: 0.1387 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1917 - acc: 0.9639 - val_loss: 0.1312 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1888 - acc: 0.9639 - val_loss: 0.1242 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1879 - acc: 0.9759 - val_loss: 0.1205 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1881 - acc: 0.9759 - val_loss: 0.1141 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1842 - acc: 0.9759 - val_loss: 0.1181 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1827 - acc: 0.9759 - val_loss: 0.1267 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1815 - acc: 0.9639 - val_loss: 0.1217 - val_acc: 1.0000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1802 - acc: 0.9639 - val_loss: 0.1116 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1770 - acc: 0.9639 - val_loss: 0.1108 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1754 - acc: 0.9639 - val_loss: 0.1073 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1734 - acc: 0.9759 - val_loss: 0.1094 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1733 - acc: 0.9639 - val_loss: 0.1117 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1708 - acc: 0.9639 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1717 - acc: 0.9759 - val_loss: 0.0943 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1698 - acc: 0.9759 - val_loss: 0.0957 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1677 - acc: 0.9639 - val_loss: 0.1039 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1655 - acc: 0.9639 - val_loss: 0.1037 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1669 - acc: 0.9639 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1627 - acc: 0.9759 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1597 - acc: 0.9639 - val_loss: 0.1014 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1612 - acc: 0.9639 - val_loss: 0.1026 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1599 - acc: 0.9639 - val_loss: 0.0957 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1647 - acc: 0.9639 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1564 - acc: 0.9759 - val_loss: 0.0846 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1534 - acc: 0.9759 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1525 - acc: 0.9639 - val_loss: 0.0925 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1538 - acc: 0.9639 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1520 - acc: 0.9639 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1486 - acc: 0.9639 - val_loss: 0.0762 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1500 - acc: 0.9759 - val_loss: 0.0737 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1495 - acc: 0.9759 - val_loss: 0.0762 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1461 - acc: 0.9759 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1462 - acc: 0.9639 - val_loss: 0.0832 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1465 - acc: 0.9639 - val_loss: 0.0799 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1425 - acc: 0.9639 - val_loss: 0.0708 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1459 - acc: 0.9759 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1432 - acc: 0.9759 - val_loss: 0.0704 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1390 - acc: 0.9759 - val_loss: 0.0767 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1402 - acc: 0.9639 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1422 - acc: 0.9639 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1388 - acc: 0.9639 - val_loss: 0.0702 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1380 - acc: 0.9759 - val_loss: 0.0635 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1375 - acc: 0.9759 - val_loss: 0.0635 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1372 - acc: 0.9759 - val_loss: 0.0645 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1330 - acc: 0.9759 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1411 - acc: 0.9639 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1373 - acc: 0.9639 - val_loss: 0.0682 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1321 - acc: 0.9639 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1322 - acc: 0.9759 - val_loss: 0.0573 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1331 - acc: 0.9759 - val_loss: 0.0584 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1311 - acc: 0.9639 - val_loss: 0.0624 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1294 - acc: 0.9639 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1290 - acc: 0.9639 - val_loss: 0.0618 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1291 - acc: 0.9639 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1269 - acc: 0.9639 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1272 - acc: 0.9639 - val_loss: 0.0589 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1258 - acc: 0.9639 - val_loss: 0.0568 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1247 - acc: 0.9639 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1253 - acc: 0.9759 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1245 - acc: 0.9759 - val_loss: 0.0527 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1235 - acc: 0.9759 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1231 - acc: 0.9639 - val_loss: 0.0569 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1227 - acc: 0.9639 - val_loss: 0.0559 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1225 - acc: 0.9639 - val_loss: 0.0525 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1205 - acc: 0.9639 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1213 - acc: 0.9639 - val_loss: 0.0525 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1216 - acc: 0.9639 - val_loss: 0.0532 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1190 - acc: 0.9639 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1188 - acc: 0.9759 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1190 - acc: 0.9759 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1196 - acc: 0.9639 - val_loss: 0.0492 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1165 - acc: 0.9639 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1175 - acc: 0.9639 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1158 - acc: 0.9639 - val_loss: 0.0454 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1157 - acc: 0.9759 - val_loss: 0.0451 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1157 - acc: 0.9639 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1143 - acc: 0.9639 - val_loss: 0.0473 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1139 - acc: 0.9639 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1131 - acc: 0.9639 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1142 - acc: 0.9759 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1134 - acc: 0.9759 - val_loss: 0.0440 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1118 - acc: 0.9639 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1114 - acc: 0.9639 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1114 - acc: 0.9759 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1108 - acc: 0.9759 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1098 - acc: 0.9639 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1100 - acc: 0.9639 - val_loss: 0.0400 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1089 - acc: 0.9759 - val_loss: 0.0398 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1095 - acc: 0.9639 - val_loss: 0.0405 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1079 - acc: 0.9639 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1079 - acc: 0.9759 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1082 - acc: 0.9639 - val_loss: 0.0401 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1090 - acc: 0.9639 - val_loss: 0.0405 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1066 - acc: 0.9639 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1064 - acc: 0.9639 - val_loss: 0.0370 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1056 - acc: 0.9759 - val_loss: 0.0381 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1054 - acc: 0.9639 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1044 - acc: 0.9759 - val_loss: 0.0394 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1052 - acc: 0.9759 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1043 - acc: 0.9759 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1033 - acc: 0.9639 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1040 - acc: 0.9759 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1043 - acc: 0.9880 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1033 - acc: 0.9880 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1068 - acc: 0.9759 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1033 - acc: 0.9759 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1022 - acc: 0.9639 - val_loss: 0.0321 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1019 - acc: 0.9880 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1011 - acc: 0.9759 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1011 - acc: 0.9639 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1000 - acc: 0.9759 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0995 - acc: 0.9759 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0989 - acc: 0.9759 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0992 - acc: 0.9639 - val_loss: 0.0314 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0989 - acc: 0.9639 - val_loss: 0.0321 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0978 - acc: 0.9639 - val_loss: 0.0338 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0987 - acc: 0.9759 - val_loss: 0.0346 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0993 - acc: 0.9759 - val_loss: 0.0321 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0972 - acc: 0.9759 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0970 - acc: 0.9639 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0966 - acc: 0.9759 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0959 - acc: 0.9759 - val_loss: 0.0308 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0959 - acc: 0.9759 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0961 - acc: 0.9759 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0950 - acc: 0.9759 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0945 - acc: 0.9759 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0959 - acc: 0.9880 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0947 - acc: 0.9759 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0958 - acc: 0.9759 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0941 - acc: 0.9759 - val_loss: 0.0292 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0946 - acc: 0.9759 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0937 - acc: 0.9759 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0946 - acc: 0.9759 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0925 - acc: 0.9759 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0925 - acc: 0.9759 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0920 - acc: 0.9759 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0918 - acc: 0.9759 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0925 - acc: 0.9759 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0911 - acc: 0.9759 - val_loss: 0.0266 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0929 - acc: 0.9759 - val_loss: 0.0243 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0920 - acc: 0.9880 - val_loss: 0.0248 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0906 - acc: 0.9880 - val_loss: 0.0263 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0914 - acc: 0.9759 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0904 - acc: 0.9759 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0898 - acc: 0.9759 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0911 - acc: 0.9880 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0902 - acc: 0.9880 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0924 - acc: 0.9759 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0896 - acc: 0.9759 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0892 - acc: 0.9759 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0890 - acc: 0.9759 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0889 - acc: 0.9759 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0877 - acc: 0.9759 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0881 - acc: 0.9759 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0871 - acc: 0.9759 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0872 - acc: 0.9759 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0866 - acc: 0.9759 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0875 - acc: 0.9880 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0870 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0866 - acc: 0.9759 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0865 - acc: 0.9759 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0861 - acc: 0.9759 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0856 - acc: 0.9759 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0852 - acc: 0.9880 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0855 - acc: 0.9759 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0844 - acc: 0.9759 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0846 - acc: 0.9759 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0849 - acc: 0.9759 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0843 - acc: 0.9759 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0841 - acc: 0.9759 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0858 - acc: 0.9639 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0839 - acc: 0.9880 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0835 - acc: 0.9759 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0850 - acc: 0.9759 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0834 - acc: 0.9759 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0829 - acc: 0.9880 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0826 - acc: 0.9759 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0820 - acc: 0.9759 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0825 - acc: 0.9759 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0824 - acc: 0.9759 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0822 - acc: 0.9759 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0817 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0823 - acc: 0.9880 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0812 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0832 - acc: 0.9759 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0807 - acc: 0.9759 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0846 - acc: 0.9759 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0801 - acc: 0.9880 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0823 - acc: 0.9759 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0817 - acc: 0.9759 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0826 - acc: 0.9759 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0802 - acc: 0.9880 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0798 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0794 - acc: 0.9880 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0788 - acc: 0.9759 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0794 - acc: 0.9759 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0792 - acc: 0.9759 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0787 - acc: 0.9759 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0786 - acc: 0.9759 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0779 - acc: 0.9759 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0792 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0782 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0774 - acc: 0.9880 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0779 - acc: 0.9759 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0771 - acc: 0.9759 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0775 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0778 - acc: 0.9880 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0766 - acc: 0.9759 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0772 - acc: 0.9759 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0770 - acc: 0.9759 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0771 - acc: 0.9759 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0762 - acc: 0.9880 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0759 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0758 - acc: 0.9880 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0753 - acc: 0.9880 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0755 - acc: 0.9759 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0787 - acc: 0.9759 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0763 - acc: 0.9880 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0747 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0742 - acc: 0.9759 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0763 - acc: 0.9759 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0759 - acc: 0.9759 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0740 - acc: 0.9759 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0759 - acc: 0.9880 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0758 - acc: 0.9880 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0751 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0737 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0750 - acc: 0.9759 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0742 - acc: 0.9759 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0733 - acc: 0.9759 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0724 - acc: 0.9880 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0734 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0748 - acc: 0.9880 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0737 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0754 - acc: 0.9759 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0742 - acc: 0.9759 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0731 - acc: 0.9759 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0727 - acc: 0.9759 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0718 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0743 - acc: 0.9880 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0735 - acc: 0.9880 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0737 - acc: 0.9880 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0725 - acc: 0.9759 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0719 - acc: 0.9759 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0729 - acc: 0.9759 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0713 - acc: 0.9759 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0709 - acc: 0.9880 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0722 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0710 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0702 - acc: 0.9880 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0707 - acc: 0.9759 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0715 - acc: 0.9759 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0723 - acc: 0.9759 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0701 - acc: 0.9759 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0714 - acc: 0.9880 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0718 - acc: 0.9880 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0707 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0702 - acc: 0.9880 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0707 - acc: 0.9759 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0700 - acc: 0.9759 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0695 - acc: 0.9880 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0692 - acc: 0.9880 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0698 - acc: 0.9880 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0693 - acc: 0.9880 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0689 - acc: 0.9880 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0691 - acc: 0.9880 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0692 - acc: 0.9880 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0689 - acc: 0.9880 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0685 - acc: 0.9880 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0684 - acc: 0.9880 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0688 - acc: 0.9880 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0689 - acc: 0.9880 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0687 - acc: 0.9880 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0695 - acc: 0.9880 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0691 - acc: 0.9880 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0677 - acc: 0.9880 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0674 - acc: 0.9880 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0676 - acc: 0.9880 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0682 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0674 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0670 - acc: 0.9880 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0675 - acc: 0.9759 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0685 - acc: 0.9759 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0671 - acc: 0.9880 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0672 - acc: 0.9880 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0670 - acc: 0.9880 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0667 - acc: 0.9880 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0693 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0668 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0671 - acc: 0.9880 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0681 - acc: 0.9759 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0664 - acc: 0.9880 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0663 - acc: 0.9880 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0658 - acc: 0.9880 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0670 - acc: 0.9880 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0667 - acc: 0.9880 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0664 - acc: 0.9880 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0657 - acc: 0.9880 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0663 - acc: 0.9759 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0667 - acc: 0.9880 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0654 - acc: 0.9880 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0651 - acc: 0.9880 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0652 - acc: 0.9880 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0652 - acc: 0.9880 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0656 - acc: 0.9880 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0652 - acc: 0.9880 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0668 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0682 - acc: 0.9880 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0647 - acc: 0.9880 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0648 - acc: 0.9759 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0671 - acc: 0.9759 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0652 - acc: 0.9759 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0645 - acc: 0.9880 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0636 - acc: 0.9880 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0668 - acc: 0.9880 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0655 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0633 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0638 - acc: 0.9880 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0652 - acc: 0.9759 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0642 - acc: 0.9880 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0632 - acc: 0.9880 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0658 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0639 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0629 - acc: 0.9880 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0631 - acc: 0.9880 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0664 - acc: 0.9759 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0656 - acc: 0.9759 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0642 - acc: 0.9759 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0626 - acc: 0.9880 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0628 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0637 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0648 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0655 - acc: 0.9880 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0626 - acc: 0.9880 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0626 - acc: 0.9880 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0630 - acc: 0.9880 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0620 - acc: 0.9880 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0625 - acc: 0.9880 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0619 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0618 - acc: 0.9880 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0629 - acc: 0.9880 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0620 - acc: 0.9880 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0612 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0624 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0623 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0618 - acc: 0.9880 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0612 - acc: 0.9880 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0617 - acc: 0.9880 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0615 - acc: 0.9880 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0610 - acc: 0.9880 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0619 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0625 - acc: 0.9880 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0608 - acc: 0.9880 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0608 - acc: 0.9880 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0607 - acc: 0.9880 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0611 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0608 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0604 - acc: 0.9880 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0602 - acc: 0.9880 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0617 - acc: 0.9880 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0625 - acc: 0.9880 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0607 - acc: 0.9880 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0603 - acc: 0.9880 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0605 - acc: 0.9880 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0603 - acc: 0.9880 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0604 - acc: 0.9880 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0598 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0603 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0611 - acc: 0.9880 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0600 - acc: 0.9880 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0594 - acc: 0.9880 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0596 - acc: 0.9880 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0597 - acc: 0.9880 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0600 - acc: 0.9880 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0610 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0600 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0592 - acc: 0.9880 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0591 - acc: 0.9880 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0591 - acc: 0.9880 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0595 - acc: 0.9880 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0591 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0591 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0590 - acc: 0.9880 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0584 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0586 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0604 - acc: 0.9880 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0586 - acc: 0.9880 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0589 - acc: 0.9880 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0582 - acc: 0.9880 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0583 - acc: 0.9880 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0585 - acc: 0.9880 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0584 - acc: 0.9880 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0580 - acc: 0.9880 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0578 - acc: 0.9880 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0582 - acc: 0.9880 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0578 - acc: 0.9880 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0582 - acc: 0.9880 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0579 - acc: 0.9880 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0576 - acc: 0.9880 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0578 - acc: 0.9880 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0578 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0590 - acc: 0.9880 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0583 - acc: 0.9880 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0571 - acc: 0.9880 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0577 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0577 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0569 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0569 - acc: 0.9880 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0568 - acc: 0.9880 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0567 - acc: 0.9880 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0568 - acc: 0.9880 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0567 - acc: 0.9880 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0568 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0567 - acc: 0.9880 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0562 - acc: 0.9880 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0566 - acc: 0.9880 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0563 - acc: 0.9880 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0566 - acc: 0.9880 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0560 - acc: 0.9880 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0565 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0557 - acc: 0.9880 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0571 - acc: 0.9880 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0555 - acc: 0.9880 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0566 - acc: 0.9880 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0557 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0550 - acc: 0.9880 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0558 - acc: 0.9880 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0570 - acc: 0.9880 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0560 - acc: 0.9880 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0562 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0559 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0562 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0551 - acc: 0.9880 - val_loss: 0.0058 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "keras_model = Sequential()\n",
    "\n",
    "# Layers\n",
    "keras_model.add(Flatten(input_shape=(4,)))\n",
    "keras_model.add(Dense(units=3,\n",
    "                      activation=\"softmax\"))\n",
    "\n",
    "# Compile\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-1),\n",
    "                    loss=\"sparse_categorical_crossentropy\",\n",
    "                    metrics=[\"acc\"])\n",
    "\n",
    "# 학습\n",
    "history = keras_model.fit(x_data_train_norm,\n",
    "                          t_data_train,\n",
    "                          epochs=500,\n",
    "                          verbose=1,\n",
    "                          validation_split=0.2)\n",
    "\n",
    "# learning_rate = 1e-2\n",
    "# 3/3 [==============================] - 0s 37ms/step - loss: 0.2190 - acc: 0.9759 - val_loss: 0.1616 - val_acc: 1.0000\n",
    "\n",
    "# learning_rate = 1e-1\n",
    "# 3/3 [==============================] - 0s 41ms/step - loss: 0.0551 - acc: 0.9880 - val_loss: 0.0058 - val_acc: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1174 - acc: 0.9111\n",
      "[0.11741314083337784, 0.9111111164093018]\n"
     ]
    }
   ],
   "source": [
    "print(keras_model.evaluate(x_data_test_norm, t_data_test))  # [0.11741314083337784, 0.9111111164093018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화를 통한 overfitting 확인\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'], color='r')\n",
    "plt.plot(history.history['val_loss'], color='b')\n",
    "plt.show()\n",
    "\n",
    "# val_loss가 더 낮음을 확인\n",
    "# loss가 우하향을 하는 것을 확인하면서 잘 만들어진 모델이라는 것을 알 수 있음"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
